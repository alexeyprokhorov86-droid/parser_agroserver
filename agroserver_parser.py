"""
–ü–∞—Ä—Å–µ—Ä —Ü–µ–Ω –Ω–∞ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã —Å Agroserver.ru
–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ä–µ–≥–∏–æ–Ω—É: –ú–æ—Å–∫–≤–∞ –∏ –ú–æ—Å–∫–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import time
from datetime import datetime

class AgroserverParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ü–µ–Ω —Å Agroserver.ru"""
    
    def __init__(self):
        self.base_url = "https://agroserver.ru"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
        }
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä—è—Ç—å)
        self.categories = {
            '–º—É–∫–∞_–ø—à–µ–Ω–∏—á–Ω–∞—è': '/muka-pshenichnaya/',
            '—Å–∞—Ö–∞—Ä': '/sakhar/',
            '–º–∞—Å–ª–æ_—Å–ª–∏–≤–æ—á–Ω–æ–µ': '/maslo-slivochnoe/',
            '–º–æ–ª–æ–∫–æ': '/moloko/',
        }
        
        # –†–µ–≥–∏–æ–Ω—ã –ú–æ—Å–∫–≤—ã –∏ –ú–û –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        self.moscow_regions = [
            '–º–æ—Å–∫–≤–∞', '–º–æ—Å–∫–æ–≤—Å–∫–∞—è', '–º–æ', 'moscow',
            '–ø–æ–¥–º–æ—Å–∫–æ–≤—å–µ', '—Ö–∏–º–∫–∏', '–±–∞–ª–∞—à–∏—Ö–∞', '–æ–¥–∏–Ω—Ü–æ–≤–æ',
            '–º—ã—Ç–∏—â–∏', '–ª—é–±–µ—Ä—Ü—ã', '–∫–æ—Ä–æ–ª–µ–≤', '–∫—Ä–∞—Å–Ω–æ–≥–æ—Ä—Å–∫'
        ]
    
    def extract_price(self, text):
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ü–µ–Ω—É –∏–∑ —Ç–µ–∫—Å—Ç–∞
        –ü—Ä–∏–º–µ—Ä—ã:
        - "25.50 —Ä—É–± / –∫–≥" -> 25.50
        - "25 000 —Ä—É–±/—Ç" -> 25.0 (–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ —Ä—É–±/–∫–≥)
        - "–æ—Ç 30 —Ä—É–±" -> 30.0
        """
        if not text:
            return None
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = ' '.join(text.split())
        
        # –ò—â–µ–º —Ü–µ–Ω—É –≤ —Ä—É–±–ª—è—Ö
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã: "25.50 —Ä—É–±", "25,50 —Ä—É–±", "25 000 —Ä—É–±"
        patterns = [
            r'(\d+[\s,.]?\d*)\s*(?:—Ä—É–±|‚ÇΩ)',  # –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω
            r'–æ—Ç\s+(\d+[\s,.]?\d*)',          # "–æ—Ç 25"
            r'(\d+[\s,.]?\d*)\s*—Ä\b',         # "25 —Ä"
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text.lower())
            if match:
                price_str = match.group(1)
                # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –∑–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É
                price_str = price_str.replace(' ', '').replace(',', '.')
                try:
                    price = float(price_str)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
                    if '/—Ç' in text.lower() or '—Ä—É–±/—Ç' in text.lower():
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ —Ä—É–±/—Ç –≤ —Ä—É–±/–∫–≥
                        price = price / 1000
                    
                    return price
                except ValueError:
                    continue
        
        return None
    
    def is_moscow_region(self, text):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –∫ –ú–æ—Å–∫–≤–µ/–ú–û
        """
        if not text:
            return False
        
        text_lower = text.lower()
        return any(region in text_lower for region in self.moscow_regions)
    
    def parse_category_page(self, category_url, max_pages=5):
        """
        –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        
        Args:
            category_url: URL –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, '/muka-pshenichnaya/')
            max_pages: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
        
        Returns:
            list: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ –æ–± –æ–±—ä—è–≤–ª–µ–Ω–∏—è—Ö
        """
        results = []
        
        for page_num in range(1, max_pages + 1):
            # –§–æ—Ä–º–∏—Ä—É–µ–º URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if page_num == 1:
                url = f"{self.base_url}{category_url}"
            else:
                url = f"{self.base_url}{category_url}p{page_num}.htm"
            
            print(f"–ü–∞—Ä—Å–∏–Ω–≥: {url}")
            
            try:
                # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å
                response = requests.get(url, headers=self.headers, timeout=10)
                response.raise_for_status()
                
                # –ü–∞—Ä—Å–∏–º HTML
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # –ò—â–µ–º –±–ª–æ–∫–∏ —Å –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º–∏
                # –í–ê–ñ–ù–û: —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–æ–∂–µ—Ç –º–µ–Ω—è—Ç—å—Å—è, –Ω—É–∂–Ω–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                ads = soup.find_all('div', class_='b-item')  # –ü—Ä–∏–º–µ—Ä–Ω—ã–π –∫–ª–∞—Å—Å
                
                if not ads:
                    # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                    ads = soup.find_all('div', class_='item')
                    
                if not ads:
                    print(f"  –ù–µ –Ω–∞–π–¥–µ–Ω—ã –æ–±—ä—è–≤–ª–µ–Ω–∏—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}")
                    break
                
                print(f"  –ù–∞–π–¥–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {len(ads)}")
                
                # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥–æ–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
                for ad in ads:
                    try:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è!)
                        title = ad.find('a', class_='title')
                        title_text = title.get_text(strip=True) if title else None
                        
                        price = ad.find('span', class_='price')
                        price_text = price.get_text(strip=True) if price else None
                        
                        location = ad.find('span', class_='location')
                        location_text = location.get_text(strip=True) if location else None
                        
                        company = ad.find('span', class_='company')
                        company_text = company.get_text(strip=True) if company else None
                        
                        # –§–∏–ª—å—Ç—Ä –ø–æ –ú–æ—Å–∫–≤–µ/–ú–û
                        if location_text and not self.is_moscow_region(location_text):
                            continue
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—É
                        price_value = self.extract_price(price_text) if price_text else None
                        
                        if price_value and price_value > 0:
                            results.append({
                                '–Ω–∞–∑–≤–∞–Ω–∏–µ': title_text,
                                '—Ü–µ–Ω–∞_—Ä—É–±_–∫–≥': price_value,
                                '—Ä–µ–≥–∏–æ–Ω': location_text,
                                '–ø–æ—Å—Ç–∞–≤—â–∏–∫': company_text,
                                '–¥–∞—Ç–∞_–ø–∞—Ä—Å–∏–Ω–≥–∞': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                            })
                    
                    except Exception as e:
                        print(f"  –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è: {e}")
                        continue
                
                # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (—á—Ç–æ–±—ã –Ω–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª–∏)
                time.sleep(2)
            
            except requests.RequestException as e:
                print(f"  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
                break
        
        return results
    
    def parse_ingredient(self, ingredient_name, category_url):
        """
        –ü–∞—Ä—Å–∏—Ç —Ü–µ–Ω—ã –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç
        
        Args:
            ingredient_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–∞ –¥–ª—è –æ—Ç—á–µ—Ç–∞
            category_url: URL –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–∞ Agroserver
        
        Returns:
            dict: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ü–µ–Ω–∞–º
        """
        print(f"\n{'='*70}")
        print(f"–ü–∞—Ä—Å–∏–Ω–≥: {ingredient_name}")
        print(f"{'='*70}")
        
        # –ü–∞—Ä—Å–∏–º –æ–±—ä—è–≤–ª–µ–Ω–∏—è
        results = self.parse_category_page(category_url, max_pages=3)
        
        if not results:
            print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ü–µ–Ω—ã –¥–ª—è: {ingredient_name}")
            return None
        
        # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        df = pd.DataFrame(results)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = {
            '–∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç': ingredient_name,
            '–Ω–∞–π–¥–µ–Ω–æ_–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π': len(df),
            '–º–∏–Ω_—Ü–µ–Ω–∞': df['—Ü–µ–Ω–∞_—Ä—É–±_–∫–≥'].min(),
            '–º–∞–∫—Å_—Ü–µ–Ω–∞': df['—Ü–µ–Ω–∞_—Ä—É–±_–∫–≥'].max(),
            '—Å—Ä–µ–¥–Ω—è—è_—Ü–µ–Ω–∞': df['—Ü–µ–Ω–∞_—Ä—É–±_–∫–≥'].mean(),
            '–º–µ–¥–∏–∞–Ω–Ω–∞—è_—Ü–µ–Ω–∞': df['—Ü–µ–Ω–∞_—Ä—É–±_–∫–≥'].median(),
            '—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è_—Ü–µ–Ω–∞': df['—Ü–µ–Ω–∞_—Ä—É–±_–∫–≥'].median(),  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–¥–∏–∞–Ω—É
            '–¥–∞—Ç–∞_–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è': datetime.now().strftime('%Y-%m-%d')
        }
        
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ü–µ–Ω–∞–º:")
        print(f"  –ù–∞–π–¥–µ–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['–Ω–∞–π–¥–µ–Ω–æ_–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π']}")
        print(f"  –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞: {stats['–º–∏–Ω_—Ü–µ–Ω–∞']:.2f} —Ä—É–±/–∫–≥")
        print(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞: {stats['–º–∞–∫—Å_—Ü–µ–Ω–∞']:.2f} —Ä—É–±/–∫–≥")
        print(f"  –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: {stats['—Å—Ä–µ–¥–Ω—è—è_—Ü–µ–Ω–∞']:.2f} —Ä—É–±/–∫–≥")
        print(f"  –ú–µ–¥–∏–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞: {stats['–º–µ–¥–∏–∞–Ω–Ω–∞—è_—Ü–µ–Ω–∞']:.2f} —Ä—É–±/–∫–≥")
        print(f"  ‚úÖ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è —Ü–µ–Ω–∞: {stats['—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è_—Ü–µ–Ω–∞']:.2f} —Ä—É–±/–∫–≥")
        
        return stats, df
    
    def update_prices_in_database(self, csv_path='ingredients_v2.csv'):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç —Ü–µ–Ω—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤
        
        Args:
            csv_path: –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É —Å –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–∞–º–∏
        """
        print(f"\n{'='*70}")
        print("–û–ë–ù–û–í–õ–ï–ù–ò–ï –¶–ï–ù –í –ë–ê–ó–ï –î–ê–ù–ù–´–•")
        print(f"{'='*70}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É
        try:
            df_ingredients = pd.read_csv(csv_path, encoding='utf-8')
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤: {len(df_ingredients)}")
        except FileNotFoundError:
            print(f"‚ùå –§–∞–π–ª {csv_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
        
        # –ú–∞–ø–ø–∏–Ω–≥ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ Agroserver
        # –≠—Ç–æ –Ω—É–∂–Ω–æ —Ä–∞—Å—à–∏—Ä—è—Ç—å –ø–æ–¥ —Ç–≤–æ–∏ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã
        ingredient_mapping = {
            '–ú—É–∫–∞ –ø—à–µ–Ω–∏—á–Ω–∞—è –≤/—Å': '/muka-pshenichnaya/',
            '–ú—É–∫–∞ –ø—à–µ–Ω–∏—á–Ω–∞—è 1 —Å': '/muka-pshenichnaya/',
            '–°–∞—Ö–∞—Ä': '/sakhar/',
            '–ú–∞—Å–ª–æ —Å–ª–∏–≤–æ—á–Ω–æ–µ 82,5%': '/maslo-slivochnoe/',
            '–ú–∞—Å–ª–æ —Å–ª–∏–≤–æ—á–Ω–æ–µ 72,5%': '/maslo-slivochnoe/',
        }
        
        updated_count = 0
        
        for ingredient_name, category_url in ingredient_mapping.items():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —ç—Ç–æ—Ç –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç –≤ –±–∞–∑–µ
            if ingredient_name not in df_ingredients['–ò–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç'].values:
                print(f"‚ö†Ô∏è –ò–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç '{ingredient_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ")
                continue
            
            # –ü–∞—Ä—Å–∏–º —Ü–µ–Ω—ã
            result = self.parse_ingredient(ingredient_name, category_url)
            
            if result:
                stats, _ = result
                recommended_price = stats['—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è_—Ü–µ–Ω–∞']
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Ü–µ–Ω—É –≤ –±–∞–∑–µ
                mask = df_ingredients['–ò–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç'] == ingredient_name
                old_price = df_ingredients.loc[mask, '–°—Ç–æ–∏–º–æ—Å—Ç—å, —Ä—É–±/–∫–≥'].values[0]
                df_ingredients.loc[mask, '–°—Ç–æ–∏–º–æ—Å—Ç—å, —Ä—É–±/–∫–≥'] = recommended_price
                
                print(f"  üí∞ –°—Ç–∞—Ä–∞—è —Ü–µ–Ω–∞: {old_price:.2f} —Ä—É–±/–∫–≥")
                print(f"  üí∞ –ù–æ–≤–∞—è —Ü–µ–Ω–∞: {recommended_price:.2f} —Ä—É–±/–∫–≥")
                print(f"  üìà –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {((recommended_price - old_price) / old_price * 100):.1f}%")
                
                updated_count += 1
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–∞–º–∏
            time.sleep(3)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –±–∞–∑—É
        if updated_count > 0:
            df_ingredients.to_csv(csv_path, index=False, encoding='utf-8')
            print(f"\n‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ —Ü–µ–Ω: {updated_count}")
            print(f"‚úÖ –ë–∞–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {csv_path}")
        else:
            print(f"\n‚ö†Ô∏è –¶–µ–Ω—ã –Ω–µ –±—ã–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")


# ============================================================================
# –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø
# ============================================================================

if __name__ == "__main__":
    parser = AgroserverParser()
    
    # –í–∞—Ä–∏–∞–Ω—Ç 1: –ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–∞
    print("\n" + "="*70)
    print("–í–ê–†–ò–ê–ù–¢ 1: –ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–∞")
    print("="*70)
    
    result = parser.parse_ingredient(
        ingredient_name='–ú—É–∫–∞ –ø—à–µ–Ω–∏—á–Ω–∞—è',
        category_url='/muka-pshenichnaya/'
    )
    
    if result:
        stats, df = result
        print(f"\nüìÑ –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º:")
        print(df.to_string(index=False))
    
    # –í–∞—Ä–∏–∞–Ω—Ç 2: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—Å–µ–π –±–∞–∑—ã
    print("\n" + "="*70)
    print("–í–ê–†–ò–ê–ù–¢ 2: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ü–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
    print("="*70)
    
    # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –∫–æ–≥–¥–∞ –±—É–¥–µ—à—å –≥–æ—Ç–æ–≤ –æ–±–Ω–æ–≤–ª—è—Ç—å –±–∞–∑—É
    # parser.update_prices_in_database('ingredients_v2.csv')
